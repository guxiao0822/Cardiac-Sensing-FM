{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b459e93bdd08a53",
   "metadata": {},
   "source": [
    "# Preprocess VTaC dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:02.248128Z",
     "start_time": "2025-06-05T14:34:01.798439Z"
    }
   },
   "source": [
    " import pandas as pd\n",
    " import wfdb\n",
    " import matplotlib.pyplot as plt\n",
    " import numpy as np\n",
    " import h5py"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8d03913706a48306",
   "metadata": {},
   "source": [
    "Each waveform recording in the [VTaC](https://physionet.org/content/vtac/1.0/)\n",
    " dataset contains at least two electrocardiogram (ECG) leads and one or more pulsatile waveforms, such as photoplethysmogram (PPG or PLETH) and arterial blood pressure (ABP) waveforms.\n",
    "\n",
    "In this demostration, we utilize the ECG signal from lead II and the PPG signal from PLETH waveform. The training, validation, and test sets were partitioned according to the official dataset split.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "67e2355697960128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:04.411857Z",
     "start_time": "2025-06-05T14:34:04.400014Z"
    }
   },
   "source": [
    "root_dir = \"/mnt/Data2/data/vtac-a-benchmark-dataset-of-ventricular-tachycardia-alarms-from-icu-monitors-1.0/\"\n",
    "data_df = pd.read_csv(root_dir + '/benchmark_data_split.csv')\n",
    "label_df = pd.read_csv(root_dir + '/event_labels.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "fb9cb202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:34:06.187202Z",
     "start_time": "2025-06-05T14:34:05.784286Z"
    }
   },
   "source": [
    "# function to get all the segments\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import heartpy as hp\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import skew\n",
    "\n",
    "def flat_sqi(signal, window=60, e=1e-5):\n",
    "    for i in range(len(signal) - window):\n",
    "        seg = signal[i:i + window]\n",
    "        d = np.diff(seg)\n",
    "        counter = sum([abs(a) < e for a in d])\n",
    "        if counter == window - 1:\n",
    "            return 1  # bad signal\n",
    "    return 0  # good signal\n",
    "\n",
    "def skewness_sqi(sig, sampling_rate, window=2, step=1, return_s=False):\n",
    "    step_size = step * sampling_rate\n",
    "    range_sample = window * sampling_rate\n",
    "    start = 0\n",
    "    end = 0\n",
    "    s = []\n",
    "    while start < len(sig) - range_sample:\n",
    "        end = start + range_sample\n",
    "        seg = sig[start:end]\n",
    "        start = start + step_size\n",
    "        s.append(skew(seg))\n",
    "    counter = [a > 0 for a in s]  # threshold for skewness is 0, i.e. positive skewed\n",
    "    if sum(counter) > 0.5 * len(s):  # if 50% skewness are positive\n",
    "        if return_s:\n",
    "            return 0, s  # good signal\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        if return_s:\n",
    "            return 1, s\n",
    "        else:\n",
    "            return 1  # bad signal\n",
    "        \n",
    "def median_absolute_deviation(x):\n",
    "    return np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "def hampel(ts, window_size=5, n=3, imputation=False):\n",
    "    if type(ts) != pd.Series:\n",
    "        ts = pd.Series(ts)\n",
    "\n",
    "    ts_cleaned = ts.copy()\n",
    "    k = 1.4826\n",
    "\n",
    "    rolling_ts = ts_cleaned.rolling(window_size * 2, center=True)\n",
    "    rolling_median = rolling_ts.median().bfill().ffill()\n",
    "    rolling_sigma = k * (rolling_ts.apply(median_absolute_deviation).bfill().ffill())\n",
    "\n",
    "    outlier_indices = list(np.array(np.where(np.abs(ts_cleaned - rolling_median) >= (n * rolling_sigma))).flatten())\n",
    "\n",
    "    if imputation:\n",
    "        ts_cleaned[outlier_indices] = rolling_median[outlier_indices]\n",
    "        return outlier_indices, np.array(ts_cleaned)\n",
    "\n",
    "    return outlier_indices\n",
    "\n",
    "def ppg_quality(ppg, fs):\n",
    "    if flat_sqi(ppg) == 1:\n",
    "        return 0, ppg\n",
    "\n",
    "    ppg = (ppg - ppg.mean()) / ppg.std()\n",
    "    ppg_p = nk.ppg_clean(ppg, sampling_rate=fs, method='elgendi')  # third order bandpass butterworth filter\n",
    "\n",
    "    try:\n",
    "        wd, m = hp.process(ppg_p, fs, windowsize=1, reject_segmentwise=True)\n",
    "    except hp.exceptions.BadSignalWarning:\n",
    "        return 0, ppg\n",
    "\n",
    "    if sum(wd['binary_peaklist']) < 5:\n",
    "        return 0, ppg\n",
    "\n",
    "    if skewness_sqi(ppg_p, fs) == 0:\n",
    "        return 1, ppg_p\n",
    "    else:\n",
    "        return 0, ppg\n",
    "\n",
    "def get_ecg_ppg_signals(seg_path, signal_duration=10, fs=250):\n",
    "    seg_path = Path(seg_path)\n",
    "    record = wfdb.rdheader(str(seg_path))\n",
    "    if 'II' not in record.sig_name or not any(\n",
    "            ppg in record.sig_name for ppg in ['PLETH', 'PLETH L', 'PLETH R']):\n",
    "        return None\n",
    "\n",
    "    # Skip the first 10 seconds\n",
    "    initial_offset = (60*5-10) * fs\n",
    "    \n",
    "    segs = wfdb.rdsamp(str(seg_path), sampfrom=initial_offset, sampto=initial_offset+10*fs)\n",
    "    idx_ecg = segs[1]['sig_name'].index('II')\n",
    "    idx_ppg = segs[1]['sig_name'].index('PLETH')\n",
    "    signal = segs[0][:, [idx_ecg, idx_ppg]]  # Get the signal segment\n",
    "    ecg_mean = np.nanmean(signal[:, 0])\n",
    "    ppg_mean = np.nanmean(signal[:, 1])\n",
    "    \n",
    "    signal[:, 0] = np.where(np.isnan(signal[:, 0]), ecg_mean, signal[:, 0])\n",
    "    signal[:, 1] = np.where(np.isnan(signal[:, 1]), ppg_mean, signal[:, 1])\n",
    "    \n",
    "    if np.isnan(signal).any():\n",
    "        return None\n",
    "    \n",
    "    ecg_cleaned = nk.ecg_clean(signal[:, 0], sampling_rate=fs)\n",
    "    ppg_sqi, ppg_cleaned = ppg_quality(signal[:, 1], fs)\n",
    "  \n",
    "    return np.stack((ecg_cleaned, ppg_cleaned), axis=0)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "eef44373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:37:20.810953Z",
     "start_time": "2025-06-05T14:34:42.509166Z"
    }
   },
   "source": [
    "train_signals = []\n",
    "train_labels = []\n",
    "\n",
    "val_signals = []\n",
    "val_labels = []\n",
    "\n",
    "test_signals = []\n",
    "test_labels = []\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "for i in tqdm(range(len(data_df))):\n",
    "    if data_df.split[i] == 'train':\n",
    "        data_path = f'{root_dir}/waveforms/{data_df.record[i]}/{data_df.event[i]}'\n",
    "        sample = get_ecg_ppg_signals(data_path)\n",
    "        label = label_df[label_df.event == data_df.event[i]].decision\n",
    "        if sample is not None:\n",
    "            train_signals.append(sample)\n",
    "            train_labels.append(label)\n",
    "    elif data_df.split[i] == 'val':\n",
    "        data_path = f'{root_dir}/waveforms/{data_df.record[i]}/{data_df.event[i]}'\n",
    "        sample = get_ecg_ppg_signals(data_path)\n",
    "        label = label_df[label_df.event == data_df.event[i]].decision\n",
    "        if sample is not None:\n",
    "            val_signals.append(sample)\n",
    "            val_labels.append(label)\n",
    "    else:\n",
    "        data_path = f'{root_dir}/waveforms/{data_df.record[i]}/{data_df.event[i]}'\n",
    "        sample = get_ecg_ppg_signals(data_path)\n",
    "        label = label_df[label_df.event == data_df.event[i]].decision\n",
    "        if sample is not None:\n",
    "            test_signals.append(sample)\n",
    "            test_labels.append(label)\n",
    "\n",
    "train_labels_new = np.array(train_labels)\n",
    "train_labels_new = [int(value) for value in train_labels_new]\n",
    "\n",
    "val_labels_new = np.array(val_labels)\n",
    "val_labels_new = [int(value) for value in val_labels_new]\n",
    "\n",
    "test_labels_new = np.array(test_labels)\n",
    "test_labels_new = [int(value) for value in test_labels_new]\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5037/5037 [02:38<00:00, 31.83it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "84ca52b08ab7297e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:37:22.643395Z",
     "start_time": "2025-06-05T14:37:22.528050Z"
    }
   },
   "source": [
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "# Create HDF5 file and save data\n",
    "\n",
    "output_h5_path = 'vtac_train.h5'\n",
    "with h5py.File(output_h5_path, 'w') as h5f:\n",
    "    h5f.create_dataset('tracings', data=train_signals)\n",
    "    h5f.create_dataset('labels', data=np.array(train_labels_new).reshape(-1,1))\n",
    "\n",
    "output_h5_path = 'vtac_val.h5'\n",
    "with h5py.File(output_h5_path, 'w') as h5f:\n",
    "    h5f.create_dataset('tracings', data=val_signals)\n",
    "    h5f.create_dataset('labels', data=np.array(val_labels_new).reshape(-1,1))\n",
    "\n",
    "output_h5_path = 'vtac_test.h5'\n",
    "with h5py.File(output_h5_path, 'w') as h5f:\n",
    "    h5f.create_dataset('tracings', data=test_signals)\n",
    "    h5f.create_dataset('labels', data=np.array(test_labels_new).reshape(-1,1))"
   ],
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LongECG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
